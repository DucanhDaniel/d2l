{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import mxnet as d2l\n",
    "from mxnet import gluon, autograd, np, npx\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the weight, bias and super parameters\n",
    "num_inputs, num_hidden1, num_hidden2, num_outputs = 28 * 28, 256, 256, 10\n",
    "learning_rate = 0.5\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "dropout_p1, dropout_p2 = 0.2, 0.5\n",
    "\n",
    "W1 = np.random.normal(scale = 0.01, size = (num_inputs, num_hidden1))\n",
    "b1 = np.zeros(shape = (1, num_hidden1))\n",
    "\n",
    "W2 = np.random.normal(scale = 0.01, size = (num_hidden1, num_hidden2))\n",
    "b2 = np.zeros(shape = (1, num_hidden2))\n",
    "\n",
    "W3 = np.random.normal(scale = 0.01, size = (num_hidden2, num_outputs))\n",
    "b3 = np.zeros(shape = (1, num_outputs))\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]\n",
    "weight = [W1, W2, W3]\n",
    "bias = [b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss cross entropy\n",
    "def loss(y_hat, y):\n",
    "    y_hat = np.softmax(y_hat, axis = 1)\n",
    "    return -np.log(y_hat[range(y_hat.shape[0]), y])\n",
    "\n",
    "def optimizer(weight, bias, learning_rate, batch_size, wd, wd_mult = 1):\n",
    "    for W in weight:\n",
    "        W[:] = W - learning_rate / batch_size * W.grad - learning_rate * wd * W\n",
    "    for b in bias:\n",
    "        b[:] = b - learning_rate / batch_size * b.grad - learning_rate * wd_mult * wd * W \n",
    "\n",
    "# Define trainer function\n",
    "def epoch_trainer(net, train_iter, wd = 0):\n",
    "    # 3 metric: train_loss, train_accuracy, total_examples\n",
    "    metric = d2l.Accumulator(3)\n",
    "\n",
    "    for X, y in train_iter:\n",
    "        with autograd.record():\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "        l.backward()\n",
    "        optimizer(weight, bias, learning_rate, batch_size, wd)\n",
    "        metric.add(l.sum(), d2l.accuracy(y_hat, y), y.size)\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def train(net, train_iter, test_iter):\n",
    "    anim = d2l.Animator(\n",
    "        xlabel=\"epochs\", legend = [\"train_loss\", \"train_accuracy\", \"test_accuracy\"]\n",
    "    )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = epoch_trainer(net, train_iter)\n",
    "        for X, y in test_iter:\n",
    "            test_acc = d2l.accuracy(net(X), y) / len(y)\n",
    "            break\n",
    "        anim.add([epoch + 1] * 3, [train_loss, train_acc, test_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
      "[[ 0.  0.  0.  0.  0. 10.  0.  0.]\n",
      " [16.  0. 20.  0. 24. 26. 28. 30.]]\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Define the dropout layer\n",
    "def dropout(X, percentage):\n",
    "    if percentage == 0:\n",
    "        return X\n",
    "    if percentage == 1:\n",
    "        return np.zeros_like(X)\n",
    "    \n",
    "    choose_index = np.random.uniform(0, 1, size = X.shape) > percentage\n",
    "    return choose_index.astype(\"float32\") * X / (1 - percentage)\n",
    "\n",
    "X = np.arange(0, 16).reshape((2, 8))\n",
    "print(X)\n",
    "print(dropout(X, 0.5))\n",
    "print(dropout(X, 0))\n",
    "print(dropout(X, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "def net(X):\n",
    "    H1 = np.dot(X, W1) + b1\n",
    "    H1 = dropout(H1, dropout_p1)\n",
    "\n",
    "    H2 = np.dot(H1, W2) + b2\n",
    "    H2 = dropout(H2, dropout_p2)\n",
    "\n",
    "    return np.dot(H2, W3) + b3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
