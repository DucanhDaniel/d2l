{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lập trình mạng nơ ron hồi tiếp từ đầu\n",
    "- Trong phần này, ta lập trình từ đầu mô hình ngôn ngữ được giới thiệu trong chương trước. Mô hình này dựa trên mạng nơ ron hồi tiếp ở cấp độ ký tự được huấn luyện trên tiểu thuyết The Time Machine. Ta bắt đầu với việc đọc tập dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "data = d2l.TimeMachine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' ', 32775), ('e', 17838), ('t', 13515), ('a', 11704), ('i', 10138), ('n', 9917), ('o', 9758), ('s', 8486), ('h', 8257), ('r', 7674), ('d', 6337), ('l', 6146), ('m', 4043), ('u', 3805), ('c', 3424), ('f', 3354), ('w', 3225), ('g', 3075), ('y', 2679), ('p', 2427), ('b', 1897), ('v', 1295), ('k', 1087), ('x', 236), ('z', 144), ('j', 97), ('q', 95)]\n"
     ]
    }
   ],
   "source": [
    "print(data.vocab.token_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = data.get_dataloader(train = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  0, 21,  ...,  0, 15, 16],\n",
      "        [ 0,  9, 10,  ...,  2, 19,  2],\n",
      "        [ 2, 23,  6,  ..., 13, 10, 21],\n",
      "        ...,\n",
      "        [ 0, 21, 19,  ...,  2, 10,  5],\n",
      "        [ 6, 19,  2,  ..., 19, 16,  4],\n",
      "        [16, 13, 13,  ..., 21, 16,  0]]) tensor([[ 0, 21, 16,  ..., 15, 16, 21],\n",
      "        [ 9, 10, 20,  ..., 19,  2,  5],\n",
      "        [23,  6, 13,  ..., 10, 21, 21],\n",
      "        ...,\n",
      "        [21, 19,  2,  ..., 10,  5,  0],\n",
      "        [19,  2,  3,  ..., 16,  4,  6],\n",
      "        [13, 13, 16,  ..., 16,  0,  4]])\n"
     ]
    }
   ],
   "source": [
    "# In ra một minibatch\n",
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'o', ' ', 'h', 'e', 'r', 'e', ' ', 's', 'u', 'r', 'e', 'l', 'y', ' ', 't', 'h', 'e', ' ', 'm', 'e', 'r', 'c', 'u', 'r', 'y', ' ', 'd', 'i', 'd', ' ', 'n', 'o', 't']\n",
      " to here surely the mercury did not\n"
     ]
    }
   ],
   "source": [
    "vocab = data.vocab\n",
    "print(vocab.to_tokens(y[0]))\n",
    "str = \"\"\n",
    "for chr in vocab.to_tokens(y[0]):\n",
    "    str += chr\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "train_iter, vocab = data.get_dataloader(train = True), data.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Biểu diễn one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Biểu diễn one-hot trong pytorch\n",
    "F.one_hot(input = torch.tensor([0, 1, 2, 3]), num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kích thước minibatch mà ta lấy mẫu ở mỗi lần là __(Kích thước batch, bước thời gian)__. Hàm one_hot biển đổi một minibatch như vậy thành một tensor 3 chiều với kích thước chiều cuối cùng bằng bộ từ vựng. Chúng ta thường xuyên chuyển vị đầu vào để có đầu ra với kích thước __(bước thời gian, kích thước batch, kích thước bộ từ vựng)__ phù hợp hơn để đưa vào mô hình chuỗi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 35])\n",
      "torch.Size([35, 32, 28])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(F.one_hot(input = X.T, num_classes= len(vocab)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Khởi tạo tham số mô hình\n",
    "- Tiếp theo ta khởi tạo các tham số cho mô hình RNN. Số nút ẩn num_hiddens là tham số có thể điều chỉnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    # Hidden layer parameters\n",
    "    W_xh = torch.rand(size = (num_inputs, num_hiddens), device = device, dtype=torch.float32)\n",
    "    W_hh = torch.rand(size = (num_hiddens, num_hiddens), device = device, dtype=torch.float32)\n",
    "    b_h = torch.zeros(size = (1, num_hiddens), device = device, dtype=torch.float32)\n",
    "\n",
    "    # Output layer parameters\n",
    "    W_hq = torch.rand(size = (num_hiddens, num_outputs), device = device, dtype=torch.float32)\n",
    "    b_q = torch.zeros(size = (1, num_outputs), device = device, dtype=torch.float32)\n",
    "\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "        param = param.to(device)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Mô hình RNN\n",
    "\n",
    "- Đầu tiên ta khởi tạo trạng thái ẩn bằng hàm init_rnn_state. Hàm này trả về tuple gồm một ndarray chứa giá trị 0 và có kích thước là (kích thước batch, số nút ẩn). \n",
    "- Trả về tuple giúp ta dễ dàng xử lý các tính huống khi trạng thái ẩn có nhiều biến (Ví dụ ta cần khởi tạp nhiều tầng được kết hợp trong rnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros(\n",
    "        size = (batch_size, num_hiddens), device = device, dtype=torch.float32\n",
    "    ), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm rnn sau định nghĩa cách tính toán trạng thái ẩn và đầu ra tại một bước thời gian. Hàm kích hoạt ở đây là tanh. Giá trị trung bình của hàm tanh là 0, khi các phần tử được phân bố đều trên trục số thực."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # Input shape: (num_steps, batch_size, vocab_size)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H = state[0]\n",
    "\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        # print(H.shape, b_h.shape)\n",
    "        H = F.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "\n",
    "    outputs = torch.concatenate(outputs, axis = 0), (H, )\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNScratch(d2l.HyperParameters):\n",
    "    def __init__(self, vocab_size, num_hiddens, get_params,\n",
    "                 init_state, forward_fn, device):\n",
    "        self.save_hyperparameters()\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "    \n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size)\n",
    "        X = X.to(dtype = torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1120, 28]) torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "num_hiddens = 512\n",
    "device = 'cuda'\n",
    "\n",
    "model = RNNScratch(len(vocab), num_hiddens, get_params, init_rnn_state, rnn, device)\n",
    "\n",
    "state = model.begin_state(X.shape[0], device)\n",
    "X = X.to(device)\n",
    "Y, new_state = model(X, state)\n",
    "\n",
    "print(Y.shape, new_state[0].shape)\n",
    "# y.shape = 35 x 32 với 35 là số step, 32 là số batch\n",
    "# Sau các step thì concat tất cả lại với nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể thấy kích thước đầu ra là (số bước x kích thước batch, kích thước bộ từ vựng), trong khi kích thước trạng thái ẩn vẫn giữ nguyên là (kích thước batch, số nút ẩn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Dự đoán\n",
    "- Trước tiên ta tạo hàm dự đoán thường xuyên được dùng để kiểm tra trong quá trình huấn luyện. Hàm này dự đoán num_prediects ký tự tiếp theo dựa trên prefix (một chuỗi chứa một vài ký tự). Ở các ký tự đầu tiên trong chuỗi, ta chỉ cập nhật trạng thái ẩn rồi sau đó mới bắt đầu tạo ra các ký tự mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"aimes new\"\n",
    "vocab[prefix[0]]\n",
    "# vocab.idx_to_token[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix, num_predicts, model, vocab, device):\n",
    "    state = model.begin_state(batch_size = 1, device = device)\n",
    "    outputs = [vocab[prefix[0]]] # chỉ số của chữ cái đầu tiên trong prefix\n",
    "    print(outputs, vocab[prefix[0]])\n",
    "    def get_input():\n",
    "        return torch.tensor(data = [outputs[-1]], device = device).reshape(1, 1)\n",
    "    \n",
    "    for y in prefix[1:]: # Tạo những chữ cái của prefix trong output và \n",
    "        _, state = model(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "\n",
    "    for i in range(num_predicts):\n",
    "        y, state = model(get_input(), state)\n",
    "        outputs.append(y.argmax(axis = 1).reshape(1))\n",
    "    \n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21] 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'time traveller cccccccccc'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('time traveller ', 10, model, vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
