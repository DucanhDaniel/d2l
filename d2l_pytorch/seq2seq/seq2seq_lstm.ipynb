{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\d2l\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train parameters\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "num_steps = 9\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d2l.MTFraEng(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.get_dataloader(train = True)\n",
    "validataion_iter = data.get_dataloader(train = False)\n",
    "\n",
    "src_vocab = data.src_vocab\n",
    "tgt_vocab = data.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'home', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['be', 'still', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['i', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['fix', 'this', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['can', 'we', 'go', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['watch', 'us', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<unk>', 'up', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['may', 'i', 'go', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['i', 'swore', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['get', 'out', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[\"i'm\", 'wet', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[\"i'm\", 'calm', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[\"i'm\", '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['go', 'away', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['i', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['i', 'did', 'ok', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(src_vocab.to_tokens(batch[0][0].tolist()))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '<unk>', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'courez', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'va', 'au', '<unk>', '!', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'je', 'le', 'refuse', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'rentre', 'chez', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'j’ai', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', '<unk>', 'moi', 'qui', 'ai', 'gagné', '?', '<eos>', '<pad>']\n",
      "['<bos>', 'tom', 'a', 'payé', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'je', 'suis', '<unk>', '!', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'viens', 'ici', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'je', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', '<unk>', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', '<unk>', 'ceci', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', '<unk>', 'ceci', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'attrapez', 'tom', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<bos>', 'je', 'suis', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(tgt_vocab.to_tokens(batch[1][0].tolist()))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self, inputs_size, embed_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(inputs_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X shape: (batch_size, num_steps) \n",
    "        embedding = self.dropout(self.embedding(X.T))\n",
    "        # embedding shape (num_steps, batch_size, embed_size)\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self, inputs_size, embed_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(inputs_size, embed_size)\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, hidden, cell):\n",
    "        # Shape of X: (batch_size)\n",
    "        X = X.unsqueeze(0)\n",
    "        # -> shape of X: (1, batch_size)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(X))\n",
    "        # shape of embedding: (1, batch_size, embed_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # shape of output = (1, batch_size, hidden_size)\n",
    "\n",
    "        preds = self.fc(outputs)\n",
    "        # shape of preds = (1, batch_size, output_size)\n",
    "        preds = preds.squeeze(0)\n",
    "\n",
    "        return preds, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module, d2l.HyperParameters):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio = 0):\n",
    "        # source shape: (batch_size, num_steps)\n",
    "        batch_size = source.shape[0]\n",
    "        # num_steps = source.shape[1]\n",
    "        target_vocab_size = len(data.tgt_vocab)\n",
    "        target_len = target.shape[1]\n",
    "\n",
    "        outputs = torch.zeros((target_len, batch_size, target_vocab_size), device=device)\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        target = target.T\n",
    "        # shape of target (target_len, batch_size)\n",
    "        x = target[0]\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            \n",
    "            x, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            # print(x.shape)\n",
    "            outputs[t] = x\n",
    "\n",
    "            # x shape: (batch_size, target_vocab_size)\n",
    "            best_guess = x.argmax(1) \n",
    "\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "\n",
    "        # shape of model outputs: (batch_size, num_steps, len(data.tgt_vocab))\n",
    "        return outputs.swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train parameters\n",
    "# num_epochs = 100\n",
    "# batch_size = 32\n",
    "# num_steps = 9\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder_input_size = len(data.src_vocab)\n",
    "decoder_input_size = len(data.tgt_vocab)\n",
    "encoder_embed_size, decoder_embed_size = 300, 300\n",
    "encoder_hidden_size, decoder_hidden_size = 1024, 1024\n",
    "encoder_num_layers = decoder_num_layers = 2\n",
    "encoder_dropout = 0\n",
    "decoder_dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(encoder_input_size, encoder_embed_size, encoder_hidden_size, encoder_num_layers, encoder_dropout)\n",
    "decoder = Decoder(decoder_input_size, decoder_embed_size, decoder_hidden_size, len(data.tgt_vocab), decoder_num_layers, decoder_dropout)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 1024]) torch.Size([2, 32, 1024])\n"
     ]
    }
   ],
   "source": [
    "X = torch.zeros(size = (32, num_steps), dtype = torch.int, device = device)\n",
    "hidden, cell = encoder(X)\n",
    "print(hidden.shape, cell.shape)\n",
    "# (num_layer, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 9])\n",
      "torch.Size([32, 9])\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for X, y, _, _ in train_iter:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(model(X.to(device), y.to(device)).device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter(f\"runs/Loss_plot\")\n",
    "# step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "pad_idx = data.tgt_vocab.token_to_idx['<pad>']\n",
    "print(pad_idx)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"seq2seq_TM.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"seq2seq_TM.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marry', 'me', '<eos>']\n",
      "['fainéant', 'oublie-le', 'faire', 'faire', 'faire', 'réveille-toi', 'attendez', 'attendez', 'ont', 'réveille-toi']\n"
     ]
    }
   ],
   "source": [
    "def predict(src_sentence, num_preds):\n",
    "    list_words = src_sentence.split()\n",
    "    list_words.append(\"<eos>\")\n",
    "    print(list_words)\n",
    "    list_tokens = [data.src_vocab.token_to_idx[word] for word in list_words]\n",
    "    \n",
    "    X = torch.tensor(list_tokens, device = device)\n",
    "    X = X.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(X)\n",
    "    X = torch.tensor(data.tgt_vocab.token_to_idx['<bos>'], device = device).reshape(1)\n",
    "    \n",
    "    result = []\n",
    "    for _ in range(num_preds):\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(X, hidden, cell)\n",
    "            X = output.argmax(1)\n",
    "        result.append(output.argmax(1).cpu().numpy()[0])\n",
    "\n",
    "    print(data.tgt_vocab.to_tokens(result))\n",
    "\n",
    "\n",
    "predict(\"marry me\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20\n",
      "Loss:  tensor(3.3360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 2 / 20\n",
      "Loss:  tensor(3.3417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['<unk>', '.', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 3 / 20\n",
      "Loss:  tensor(3.3008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 4 / 20\n",
      "Loss:  tensor(2.9587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', '<unk>', '!', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 5 / 20\n",
      "Loss:  tensor(2.7434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sois', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 6 / 20\n",
      "Loss:  tensor(2.7328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 7 / 20\n",
      "Loss:  tensor(2.7844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 8 / 20\n",
      "Loss:  tensor(2.6437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'avoir', 'avoir']\n",
      "None\n",
      "Epoch: 9 / 20\n",
      "Loss:  tensor(2.5562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'ferme-la', '!', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 10 / 20\n",
      "Loss:  tensor(2.6518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux']\n",
      "None\n",
      "Epoch: 11 / 20\n",
      "Loss:  tensor(2.3283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux']\n",
      "None\n",
      "Epoch: 12 / 20\n",
      "Loss:  tensor(2.5063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 13 / 20\n",
      "Loss:  tensor(2.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['chaud', 'chaud', 'sérieux', 'sérieux', 'sérieux', 'sérieux', 'sérieux', \"c'est\", '<unk>', '!']\n",
      "None\n",
      "Epoch: 14 / 20\n",
      "Loss:  tensor(2.1547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'chaud', 'sérieux', 'sérieux', 'sérieux', 'sérieux', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 15 / 20\n",
      "Loss:  tensor(2.2668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'sérieux', 'sérieux', 'réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 16 / 20\n",
      "Loss:  tensor(2.2112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['sérieux', 'sérieux', 'réveillez-vous', 'réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 17 / 20\n",
      "Loss:  tensor(2.3765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['réveillez-vous', 'réveillez-vous', 'réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 18 / 20\n",
      "Loss:  tensor(2.2401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['réveillez-vous', 'réveillez-vous', 'réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 19 / 20\n",
      "Loss:  tensor(2.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n",
      "Epoch: 20 / 20\n",
      "Loss:  tensor(2.1400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['marry', 'me', '<eos>']\n",
      "['réveillez-vous', '!', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch + 1} / {num_epochs}\")\n",
    "    checkpoint = {'state_dict' : model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    # save_checkpoint(checkpoint)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iter):\n",
    "        # batch = batch.to(device)\n",
    "        X, y, _, _ = batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        model.train()\n",
    "        output = model(X, y)\n",
    "        # output shape: (batch_size, num_steps, len(data.tgt_vocab))\n",
    "        output = output[1:].reshape(-1, output.shape[-1])\n",
    "        y = y[1:].reshape(-1, )\n",
    "        l = loss_fn(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Loss: \", l) \n",
    "    print(predict(\"marry me\", 10))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', '<eos>']\n",
      "[\"j'ai\", '<unk>', '.', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "predict(\"i am\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
