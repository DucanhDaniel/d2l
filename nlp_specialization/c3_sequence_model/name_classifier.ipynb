{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40319f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Using device = {torch.get_default_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e47244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# We can use \"_\" to represent an out-of-vocabulary character, that is, any character we are not handling in our model\n",
    "allowed_characters = string.ascii_letters + \" .,;'\" + \"_\"\n",
    "n_letters = len(allowed_characters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in allowed_characters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f41933f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting 'Ślusàrski' to Slusarski\n",
      "converting 'Ánh Như' to Anh Nhu\n"
     ]
    }
   ],
   "source": [
    "print (f\"converting 'Ślusàrski' to {unicodeToAscii('Ślusàrski')}\")\n",
    "print (f\"converting 'Ánh Như' to {unicodeToAscii('Ánh Như')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0869b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning names into tensors\n",
    "def letterToIndex(letter):\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find('_')\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "# Turn a line into a <line_length, 1, n_letters>\n",
    "# an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc5b8bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The letter 'a' becomes tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "The name 'Ahn' becomes tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print (f\"The letter 'a' becomes {lineToTensor('a')}\") #notice that the first position in the tensor = 1\n",
    "print (f\"The name 'Ahn' becomes {lineToTensor('Ahn')}\") #notice 'A' sets the 27th index to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d2c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.load_time = time.localtime\n",
    "        labels_set = set()\n",
    "\n",
    "        self.data = []\n",
    "        self.data_tensors = []\n",
    "        self.labels = []\n",
    "        self.labels_tensors = []\n",
    "\n",
    "        #read all the ``.txt`` files in the specified directory\n",
    "        text_files = glob.glob(os.path.join(data_dir, '*.txt'))\n",
    "        for filename in text_files:\n",
    "            label = os.path.splitext(os.path.basename(filename))[0]\n",
    "            labels_set.add(label)\n",
    "            lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "            for name in lines:\n",
    "                self.data.append(name)\n",
    "                self.data_tensors.append(lineToTensor(name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "        #Cache the tensor representation of the labels\n",
    "        self.labels_uniq = list(labels_set)\n",
    "        for idx in range(len(self.labels)):\n",
    "            temp_tensor = torch.tensor([self.labels_uniq.index(self.labels[idx])], dtype=torch.long)\n",
    "            self.labels_tensors.append(temp_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_item = self.data[index]\n",
    "        data_label = self.labels[index]\n",
    "        data_tensor = self.data_tensors[index]\n",
    "        label_tensor = self.labels_tensors[index]\n",
    "\n",
    "        return label_tensor, data_tensor, data_label, data_item\n",
    "# data: Person's names\n",
    "# labels: Country names\n",
    "# data_tensor: One-hot encoded for every single letter of a person's name\n",
    "# label_tensor: Country index name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "701cff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 20074 items of data\n",
      "example = (tensor([10], device='cuda:0'), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'), 'Arabic', 'Khoury')\n"
     ]
    }
   ],
   "source": [
    "alldata = NamesDataset(\"data/names\")\n",
    "print(f\"loaded {len(alldata)} items of data\")\n",
    "print(f\"example = {alldata[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdafde65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train examples = 17063,         validation examples = 3011\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(alldata, [.85, .15], generator = torch.Generator(device = device).manual_seed(1234))\n",
    "print(\n",
    "    f\"train examples = {len(train_set)}, \\\n",
    "        validation examples = {len(test_set)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17508a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, line_tensor):\n",
    "        # hidden_shape: (1, batch_size, hidden_size)\n",
    "        # rnn_out_shape: (seq_length, batch_size, hidden_size)\n",
    "        # rnn_out chứa tất cả các hidden_states tại mỗi bước thời gian trong chuỗi đầu vào\n",
    "        rnn_out, hidden = self.rnn(line_tensor)\n",
    "        output = self.hidden_to_output(hidden[-1])\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0b824f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (rnn): RNN(58, 128)\n",
      "  (hidden_to_output): Linear(in_features=128, out_features=18, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "rnn = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de68244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8695, -2.8808, -3.1704, -2.9225, -2.7958, -2.8329, -2.9179, -2.8691,\n",
      "         -2.8430, -2.9901, -2.8501, -2.9606, -2.8588, -2.8739, -2.8363, -2.9604,\n",
      "         -2.8043, -2.8520]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
      "('Korean', 4)\n"
     ]
    }
   ],
   "source": [
    "def label_from_output(output : torch.Tensor, output_labels):\n",
    "    label_i = output.argmax(dim = 1).item()\n",
    "    return output_labels[label_i], label_i\n",
    "\n",
    "input = lineToTensor('Albert')\n",
    "output = rnn(input) #this is equivalent to ``output = rnn.forward(input)``\n",
    "print(output)\n",
    "print(label_from_output(output, alldata.labels_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train(rnn, training_data, testing_data, n_epoch = 10, batch_size = 64\n",
    ", lr = 0.2, \n",
    "          loss_fn = nn.NLLLoss()):\n",
    "    current_loss = 0\n",
    "    all_training_losses = []\n",
    "    all_valid_losses = []\n",
    "    optimizer = torch.optim.SGD(rnn.parameters(), lr = lr)\n",
    "\n",
    "    print(f\"Training on dataset with n = len({len(training_data)})\")\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        rnn.train()\n",
    "        rnn.zero_grad()\n",
    "\n",
    "        batches = list(range(len(training_data)))\n",
    "        random.shuffle(batches)\n",
    "        batches = np.array_split(batches, len(batches) // batch_size)\n",
    "\n",
    "        for idx, batch in enumerate(batches):\n",
    "            batch_loss = 0\n",
    "            for i in batch:\n",
    "                (label_tensor, text_tensor, label, text) = training_data[i]\n",
    "                label_tensor = label_tensor.to(device)\n",
    "                text_tensor = text_tensor.to(device)\n",
    "                output = rnn.forward(text_tensor)\n",
    "                loss = loss_fn(output, label_tensor)\n",
    "                batch_loss += loss\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(rnn.parameters(), 3)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            current_loss += batch_loss.item() / len(batch)\n",
    "        all_training_losses.append(current_loss / len(batches))\n",
    "\n",
    "        rnn.eval()\n",
    "        for example in testing_data:\n",
    "            with torch.no_grad():\n",
    "                (label_tensor, text_tensor, label, text) = example\n",
    "                label_tensor = label_tensor.to(device)\n",
    "                text_tensor = text_tensor.to(device)\n",
    "                output = rnn.forward(text_tensor)\n",
    "                loss = loss_fn(output, label_tensor)\n",
    "                valid_loss += loss.item()\n",
    "        all_valid_losses.append(valid_loss / len(testing_data))\n",
    "\n",
    "\n",
    "        print(f\"{epoch} ({epoch / n_epoch:.0%}): \\t average batch loss = {all_training_losses[-1]} \\t average valid loss = {all_valid_losses[-1]}\")\n",
    "        current_loss = 0\n",
    "    return all_training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2f1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset with n = len(17063)\n",
      "0 (0%): \t average batch loss = 1.7867365752706093\n",
      "1 (2%): \t average batch loss = 1.52870933800298\n",
      "2 (4%): \t average batch loss = 1.4293270036448902\n",
      "3 (6%): \t average batch loss = 1.3543094997326028\n",
      "4 (8%): \t average batch loss = 1.2932851547309605\n",
      "5 (10%): \t average batch loss = 1.2264714142881838\n",
      "6 (12%): \t average batch loss = 1.179814004508521\n",
      "7 (14%): \t average batch loss = 1.144275048838798\n",
      "8 (16%): \t average batch loss = 1.1188107586720557\n",
      "9 (18%): \t average batch loss = 1.0984487546876098\n",
      "10 (20%): \t average batch loss = 1.078674018510578\n",
      "11 (22%): \t average batch loss = 1.0593519200025232\n",
      "12 (24%): \t average batch loss = 1.0432291456596778\n",
      "13 (26%): \t average batch loss = 1.0295820745655122\n",
      "14 (28%): \t average batch loss = 1.016826717559832\n",
      "15 (30%): \t average batch loss = 1.0025124087610846\n",
      "16 (32%): \t average batch loss = 0.9914922208197205\n",
      "17 (34%): \t average batch loss = 0.9792706969399337\n",
      "18 (36%): \t average batch loss = 0.9673910226933592\n",
      "19 (38%): \t average batch loss = 0.9590340491800105\n",
      "20 (40%): \t average batch loss = 0.9505876045753806\n",
      "21 (42%): \t average batch loss = 0.9386968944788393\n",
      "22 (44%): \t average batch loss = 0.9304506244895222\n",
      "23 (46%): \t average batch loss = 0.9218006798268191\n",
      "24 (48%): \t average batch loss = 0.9125869054026242\n",
      "25 (50%): \t average batch loss = 0.9044410378757829\n",
      "26 (52%): \t average batch loss = 0.896979125701602\n",
      "27 (54%): \t average batch loss = 0.8886951241622845\n",
      "28 (56%): \t average batch loss = 0.8820039487440094\n",
      "29 (58%): \t average batch loss = 0.873315618457375\n",
      "30 (60%): \t average batch loss = 0.8657245288786687\n",
      "31 (62%): \t average batch loss = 0.8578125127500161\n",
      "32 (64%): \t average batch loss = 0.8520784031731191\n",
      "33 (66%): \t average batch loss = 0.8441993116815356\n",
      "34 (68%): \t average batch loss = 0.8391922274599054\n",
      "35 (70%): \t average batch loss = 0.8323209146928622\n",
      "36 (72%): \t average batch loss = 0.8271249689553913\n",
      "37 (74%): \t average batch loss = 0.8177993731908263\n",
      "38 (76%): \t average batch loss = 0.8125662536083996\n",
      "39 (78%): \t average batch loss = 0.8066195272534069\n",
      "40 (80%): \t average batch loss = 0.8012076281825541\n",
      "41 (82%): \t average batch loss = 0.7976162021666197\n",
      "42 (84%): \t average batch loss = 0.7893862818830477\n",
      "43 (86%): \t average batch loss = 0.7868301867904381\n",
      "44 (88%): \t average batch loss = 0.7818633210407371\n",
      "45 (90%): \t average batch loss = 0.7755438076839617\n",
      "46 (92%): \t average batch loss = 0.7712387986149383\n",
      "47 (94%): \t average batch loss = 0.7669722827529548\n",
      "48 (96%): \t average batch loss = 0.761871321539854\n",
      "49 (98%): \t average batch loss = 0.7567181601456786\n",
      "Training_time = -1000.0365533828735\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rnn.to(device)\n",
    "all_losses = train(rnn, train_set, n_epoch = 50, lr = 0.01)\n",
    "end = time.time()\n",
    "print(f\"Training_time = {start - end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c7ff27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(), \"../c3_sequence_model/name_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09c80dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arabic', 10)\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor('Tuma')\n",
    "output = rnn(input) #this is equivalent to ``output = rnn.forward(input)``\n",
    "# print(output)\n",
    "print(label_from_output(output, alldata.labels_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6579fb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7867365752706093,\n",
       " 1.52870933800298,\n",
       " 1.4293270036448902,\n",
       " 1.3543094997326028,\n",
       " 1.2932851547309605,\n",
       " 1.2264714142881838,\n",
       " 1.179814004508521,\n",
       " 1.144275048838798,\n",
       " 1.1188107586720557,\n",
       " 1.0984487546876098,\n",
       " 1.078674018510578,\n",
       " 1.0593519200025232,\n",
       " 1.0432291456596778,\n",
       " 1.0295820745655122,\n",
       " 1.016826717559832,\n",
       " 1.0025124087610846,\n",
       " 0.9914922208197205,\n",
       " 0.9792706969399337,\n",
       " 0.9673910226933592,\n",
       " 0.9590340491800105,\n",
       " 0.9505876045753806,\n",
       " 0.9386968944788393,\n",
       " 0.9304506244895222,\n",
       " 0.9218006798268191,\n",
       " 0.9125869054026242,\n",
       " 0.9044410378757829,\n",
       " 0.896979125701602,\n",
       " 0.8886951241622845,\n",
       " 0.8820039487440094,\n",
       " 0.873315618457375,\n",
       " 0.8657245288786687,\n",
       " 0.8578125127500161,\n",
       " 0.8520784031731191,\n",
       " 0.8441993116815356,\n",
       " 0.8391922274599054,\n",
       " 0.8323209146928622,\n",
       " 0.8271249689553913,\n",
       " 0.8177993731908263,\n",
       " 0.8125662536083996,\n",
       " 0.8066195272534069,\n",
       " 0.8012076281825541,\n",
       " 0.7976162021666197,\n",
       " 0.7893862818830477,\n",
       " 0.7868301867904381,\n",
       " 0.7818633210407371,\n",
       " 0.7755438076839617,\n",
       " 0.7712387986149383,\n",
       " 0.7669722827529548,\n",
       " 0.761871321539854,\n",
       " 0.7567181601456786]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef7e7a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "rnn_test = CharRNN(n_letters, n_hidden, len(alldata.labels_uniq))\n",
    "# rnn_test.load_state_dict(\"../c3_sequence_model/name_classifier.pth\")\n",
    "rnn_test.load_state_dict(torch.load(\"../c3_sequence_model/name_classifier.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e381b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy: 0.7705081368316175 in total 3011 examples!\n"
     ]
    }
   ],
   "source": [
    "def accuracy(rnn):\n",
    "    right_choice = 0\n",
    "    for example in test_set:\n",
    "        (label_tensor, text_tensor, label, text) = example\n",
    "        output = rnn(text_tensor)\n",
    "        # print(output.argmax(dim = 1))\n",
    "        # print(label_tensor)\n",
    "        if (output.argmax(dim = 1) == label_tensor): \n",
    "            right_choice += 1\n",
    "\n",
    "    return right_choice * 1.0 / len(test_set)\n",
    "\n",
    "acc = accuracy(rnn_test)\n",
    "print(f\"Model's accuracy: {acc} in total {len(test_set)} examples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "892dc95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('English', 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_choice(rnn, name):\n",
    "    input = lineToTensor(name)\n",
    "    output = rnn(input) \n",
    "    return label_from_output(output, alldata.labels_uniq)\n",
    "\n",
    "get_choice(rnn_test, \"David\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
